{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Data Preprocessing\n",
    "\n",
    "In any machine learning task, cleaning or preprocessing the data is as important as model building if not more. And when it comes to unstructured data like text, this process is even more important.\n",
    "\n",
    "Objective of this notebook is to understand the various text preprocessing steps with code examples.\n",
    "\n",
    "Some of the common text preprocessing / cleaning steps are:\n",
    "\n",
    "* Lower casing\n",
    "* Removal of Punctuations\n",
    "* Removal of Stopwords\n",
    "* Removal of Frequent words\n",
    "* Removal of Rare words\n",
    "* Stemming\n",
    "* Lemmatization\n",
    "* Removal of emojis\n",
    "* Removal of URLs\n",
    "\n",
    "\n",
    "So these are the different types of text preprocessing steps which we can do on text data. But we need not do all of these all the times. We need to carefully choose the preprocessing steps based on our use case since that also play an important role.\n",
    "\n",
    "For example, in sentiment analysis use case, we need not remove the emojis as it will convey some important information about the sentiment. Similarly we need to decide based on our use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/text.csv',lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@161252 What's that egg website people talk about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@693975 We can assist you. We recommend updati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@331912 @115955 Thats better than having an un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica is probably one of the best air...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @161252 What's that egg website people talk about\n",
       "1  Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...\n",
       "2  @693975 We can assist you. We recommend updati...\n",
       "3  @331912 @115955 Thats better than having an un...\n",
       "4  @VirginAmerica is probably one of the best air..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower Casing\n",
    "Lower casing is a common text preprocessing technique. The idea is to convert the input text into same casing format so that 'text', 'Text' and 'TEXT' are treated the same way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@161252 What's that egg website people talk about</td>\n",
       "      <td>@161252 what's that egg website people talk about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...</td>\n",
       "      <td>why!ü§∑üèª‚Äç‚ôÄÔ∏è #ios11 @applesupport https://t.co/bx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@693975 We can assist you. We recommend updati...</td>\n",
       "      <td>@693975 we can assist you. we recommend updati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@331912 @115955 Thats better than having an un...</td>\n",
       "      <td>@331912 @115955 thats better than having an un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica is probably one of the best air...</td>\n",
       "      <td>@virginamerica is probably one of the best air...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @161252 What's that egg website people talk about   \n",
       "1  Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...   \n",
       "2  @693975 We can assist you. We recommend updati...   \n",
       "3  @331912 @115955 Thats better than having an un...   \n",
       "4  @VirginAmerica is probably one of the best air...   \n",
       "\n",
       "                                          text_lower  \n",
       "0  @161252 what's that egg website people talk about  \n",
       "1  why!ü§∑üèª‚Äç‚ôÄÔ∏è #ios11 @applesupport https://t.co/bx...  \n",
       "2  @693975 we can assist you. we recommend updati...  \n",
       "3  @331912 @115955 thats better than having an un...  \n",
       "4  @virginamerica is probably one of the best air...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text_lower\"] = df[\"text\"].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of Punctuations\n",
    "\n",
    "One another common text preprocessing technique is to remove the punctuations from the text data. This is again a text standardization process that will help to treat 'hurray' and 'hurray!' in the same way.\n",
    "\n",
    "We also need to carefully choose the list of punctuations to exclude depending on the use case. For example, the string.punctuation in python contains the following punctuation symbols !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_{|}~`\n",
    "\n",
    "We can add or remove more punctuations as per our need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@161252 What's that egg website people talk about</td>\n",
       "      <td>161252 Whats that egg website people talk about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...</td>\n",
       "      <td>Whyü§∑üèª‚Äç‚ôÄÔ∏è iOS11 AppleSupport httpstcoBXrVfeIXxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@693975 We can assist you. We recommend updati...</td>\n",
       "      <td>693975 We can assist you We recommend updating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@331912 @115955 Thats better than having an un...</td>\n",
       "      <td>331912 115955 Thats better than having an unst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica is probably one of the best air...</td>\n",
       "      <td>VirginAmerica is probably one of the best airl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @161252 What's that egg website people talk about   \n",
       "1  Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...   \n",
       "2  @693975 We can assist you. We recommend updati...   \n",
       "3  @331912 @115955 Thats better than having an un...   \n",
       "4  @VirginAmerica is probably one of the best air...   \n",
       "\n",
       "                                       text_wo_punct  \n",
       "0    161252 Whats that egg website people talk about  \n",
       "1     Whyü§∑üèª‚Äç‚ôÄÔ∏è iOS11 AppleSupport httpstcoBXrVfeIXxq  \n",
       "2  693975 We can assist you We recommend updating...  \n",
       "3  331912 115955 Thats better than having an unst...  \n",
       "4  VirginAmerica is probably one of the best airl...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the new column created in last cell\n",
    "df.drop([\"text_lower\"], axis=1, inplace=True)\n",
    "\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "df[\"text_wo_punct\"] = df[\"text\"].apply(lambda text: remove_punctuation(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of stopwords\n",
    "Stopwords are commonly occuring words in a language like 'the', 'a' and so on. They can be removed from the text most of the times, as they don't provide valuable information for downstream analysis. In cases like Part of Speech tagging, we should not remove them as provide very valuable information about the POS.\n",
    "\n",
    "These stopword lists are already compiled for different languages and we can safely use them. For example, the stopword list for english language from the nltk package can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\", \".join(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_wo_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@161252 What's that egg website people talk about</td>\n",
       "      <td>161252 Whats that egg website people talk about</td>\n",
       "      <td>161252 Whats egg website people talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...</td>\n",
       "      <td>Whyü§∑üèª‚Äç‚ôÄÔ∏è iOS11 AppleSupport httpstcoBXrVfeIXxq</td>\n",
       "      <td>Whyü§∑üèª‚Äç‚ôÄÔ∏è iOS11 AppleSupport httpstcoBXrVfeIXxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@693975 We can assist you. We recommend updati...</td>\n",
       "      <td>693975 We can assist you We recommend updating...</td>\n",
       "      <td>693975 We assist We recommend updating iOS 111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@331912 @115955 Thats better than having an un...</td>\n",
       "      <td>331912 115955 Thats better than having an unst...</td>\n",
       "      <td>331912 115955 Thats better unstable connection...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica is probably one of the best air...</td>\n",
       "      <td>VirginAmerica is probably one of the best airl...</td>\n",
       "      <td>VirginAmerica probably one best airlines Ive e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @161252 What's that egg website people talk about   \n",
       "1  Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...   \n",
       "2  @693975 We can assist you. We recommend updati...   \n",
       "3  @331912 @115955 Thats better than having an un...   \n",
       "4  @VirginAmerica is probably one of the best air...   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0    161252 Whats that egg website people talk about   \n",
       "1     Whyü§∑üèª‚Äç‚ôÄÔ∏è iOS11 AppleSupport httpstcoBXrVfeIXxq   \n",
       "2  693975 We can assist you We recommend updating...   \n",
       "3  331912 115955 Thats better than having an unst...   \n",
       "4  VirginAmerica is probably one of the best airl...   \n",
       "\n",
       "                                        text_wo_stop  \n",
       "0               161252 Whats egg website people talk  \n",
       "1     Whyü§∑üèª‚Äç‚ôÄÔ∏è iOS11 AppleSupport httpstcoBXrVfeIXxq  \n",
       "2  693975 We assist We recommend updating iOS 111...  \n",
       "3  331912 115955 Thats better unstable connection...  \n",
       "4  VirginAmerica probably one best airlines Ive e...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "df[\"text_wo_stop\"] = df[\"text_wo_punct\"].apply(lambda text: remove_stopwords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of Frequent words\n",
    "In the previos preprocessing step, we removed the stopwords based on language information. But say, if we have a domain specific corpus, we might also have some frequent words which are of not so much importance to us.\n",
    "\n",
    "So this step is to remove the frequent words in the given corpus. If we use something like tfidf, this is automatically taken care of.\n",
    "\n",
    "Let us get the most common words adn then remove them in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 1557),\n",
       " ('us', 828),\n",
       " ('DM', 617),\n",
       " ('help', 436),\n",
       " ('Please', 436),\n",
       " ('Hi', 373),\n",
       " ('We', 351),\n",
       " ('get', 347),\n",
       " ('Thanks', 323),\n",
       " ('please', 305)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for text in df[\"text_wo_stop\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "        \n",
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_wo_stopfreq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@161252 What's that egg website people talk about</td>\n",
       "      <td>161252 Whats that egg website people talk about</td>\n",
       "      <td>161252 Whats egg website people talk</td>\n",
       "      <td>161252 Whats egg website people talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...</td>\n",
       "      <td>Whyü§∑üèª‚Äç‚ôÄÔ∏è iOS11 AppleSupport httpstcoBXrVfeIXxq</td>\n",
       "      <td>Whyü§∑üèª‚Äç‚ôÄÔ∏è iOS11 AppleSupport httpstcoBXrVfeIXxq</td>\n",
       "      <td>Whyü§∑üèª‚Äç‚ôÄÔ∏è iOS11 AppleSupport httpstcoBXrVfeIXxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@693975 We can assist you. We recommend updati...</td>\n",
       "      <td>693975 We can assist you We recommend updating...</td>\n",
       "      <td>693975 We assist We recommend updating iOS 111...</td>\n",
       "      <td>693975 assist recommend updating iOS 1111 have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@331912 @115955 Thats better than having an un...</td>\n",
       "      <td>331912 115955 Thats better than having an unst...</td>\n",
       "      <td>331912 115955 Thats better unstable connection...</td>\n",
       "      <td>331912 115955 Thats better unstable connection...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica is probably one of the best air...</td>\n",
       "      <td>VirginAmerica is probably one of the best airl...</td>\n",
       "      <td>VirginAmerica probably one best airlines Ive e...</td>\n",
       "      <td>VirginAmerica probably one best airlines Ive e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @161252 What's that egg website people talk about   \n",
       "1  Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...   \n",
       "2  @693975 We can assist you. We recommend updati...   \n",
       "3  @331912 @115955 Thats better than having an un...   \n",
       "4  @VirginAmerica is probably one of the best air...   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0    161252 Whats that egg website people talk about   \n",
       "1     Whyü§∑üèª‚Äç‚ôÄÔ∏è iOS11 AppleSupport httpstcoBXrVfeIXxq   \n",
       "2  693975 We can assist you We recommend updating...   \n",
       "3  331912 115955 Thats better than having an unst...   \n",
       "4  VirginAmerica is probably one of the best airl...   \n",
       "\n",
       "                                        text_wo_stop  \\\n",
       "0               161252 Whats egg website people talk   \n",
       "1     Whyü§∑üèª‚Äç‚ôÄÔ∏è iOS11 AppleSupport httpstcoBXrVfeIXxq   \n",
       "2  693975 We assist We recommend updating iOS 111...   \n",
       "3  331912 115955 Thats better unstable connection...   \n",
       "4  VirginAmerica probably one best airlines Ive e...   \n",
       "\n",
       "                                    text_wo_stopfreq  \n",
       "0               161252 Whats egg website people talk  \n",
       "1     Whyü§∑üèª‚Äç‚ôÄÔ∏è iOS11 AppleSupport httpstcoBXrVfeIXxq  \n",
       "2  693975 assist recommend updating iOS 1111 have...  \n",
       "3  331912 115955 Thats better unstable connection...  \n",
       "4  VirginAmerica probably one best airlines Ive e...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FREQWORDS = set([w for (w, wc) in cnt.most_common(10)])\n",
    "def remove_freqwords(text):\n",
    "    \"\"\"custom function to remove the frequent words\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in FREQWORDS])\n",
    "\n",
    "df[\"text_wo_stopfreq\"] = df[\"text_wo_stop\"].apply(lambda text: remove_freqwords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of Rare words\n",
    "This is very similar to previous preprocessing step but we will remove the rare words from the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_stopfreq</th>\n",
       "      <th>text_wo_stopfreqrare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@161252 What's that egg website people talk about</td>\n",
       "      <td>161252 Whats egg website people talk</td>\n",
       "      <td>161252 Whats egg website people talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...</td>\n",
       "      <td>Whyü§∑üèª‚Äç‚ôÄÔ∏è iOS11 AppleSupport httpstcoBXrVfeIXxq</td>\n",
       "      <td>Whyü§∑üèª‚Äç‚ôÄÔ∏è iOS11 AppleSupport httpstcoBXrVfeIXxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@693975 We can assist you. We recommend updati...</td>\n",
       "      <td>693975 assist recommend updating iOS 1111 have...</td>\n",
       "      <td>693975 assist recommend updating iOS 1111 have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@331912 @115955 Thats better than having an un...</td>\n",
       "      <td>331912 115955 Thats better unstable connection...</td>\n",
       "      <td>331912 115955 Thats better unstable connection...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica is probably one of the best air...</td>\n",
       "      <td>VirginAmerica probably one best airlines Ive e...</td>\n",
       "      <td>VirginAmerica probably one best airlines Ive e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @161252 What's that egg website people talk about   \n",
       "1  Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...   \n",
       "2  @693975 We can assist you. We recommend updati...   \n",
       "3  @331912 @115955 Thats better than having an un...   \n",
       "4  @VirginAmerica is probably one of the best air...   \n",
       "\n",
       "                                    text_wo_stopfreq  \\\n",
       "0               161252 Whats egg website people talk   \n",
       "1     Whyü§∑üèª‚Äç‚ôÄÔ∏è iOS11 AppleSupport httpstcoBXrVfeIXxq   \n",
       "2  693975 assist recommend updating iOS 1111 have...   \n",
       "3  331912 115955 Thats better unstable connection...   \n",
       "4  VirginAmerica probably one best airlines Ive e...   \n",
       "\n",
       "                                text_wo_stopfreqrare  \n",
       "0               161252 Whats egg website people talk  \n",
       "1     Whyü§∑üèª‚Äç‚ôÄÔ∏è iOS11 AppleSupport httpstcoBXrVfeIXxq  \n",
       "2  693975 assist recommend updating iOS 1111 have...  \n",
       "3  331912 115955 Thats better unstable connection...  \n",
       "4  VirginAmerica probably one best airlines Ive e...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the two columns which are no more needed \n",
    "df.drop([\"text_wo_punct\", \"text_wo_stop\"], axis=1, inplace=True)\n",
    "\n",
    "n_rare_words = 10\n",
    "RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
    "def remove_rarewords(text):\n",
    "    \"\"\"custom function to remove the rare words\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])\n",
    "\n",
    "df[\"text_wo_stopfreqrare\"] = df[\"text_wo_stopfreq\"].apply(lambda text: remove_rarewords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine all the list of words (stopwords, frequent words and rare words) and create a single list to remove them at once as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root form (From Wikipedia)\n",
    "\n",
    "For example, if there are two words in the corpus walks and walking, then stemming will stem the suffix to make them walk. But say in another example, we have two words console and consoling, the stemmer will remove the suffix and make them consol which is not a proper english word.\n",
    "\n",
    "There are several type of stemming algorithms available and one of the famous one is porter stemmer which is widely used. We can use nltk package for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@161252 What's that egg website people talk about</td>\n",
       "      <td>@161252 what' that egg websit peopl talk about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...</td>\n",
       "      <td>why!ü§∑üèª‚Äç‚ôÄÔ∏è #ios11 @applesupport https://t.co/bx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@693975 We can assist you. We recommend updati...</td>\n",
       "      <td>@693975 We can assist you. We recommend updat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@331912 @115955 Thats better than having an un...</td>\n",
       "      <td>@331912 @115955 that better than have an unsta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica is probably one of the best air...</td>\n",
       "      <td>@virginamerica is probabl one of the best airl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @161252 What's that egg website people talk about   \n",
       "1  Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...   \n",
       "2  @693975 We can assist you. We recommend updati...   \n",
       "3  @331912 @115955 Thats better than having an un...   \n",
       "4  @VirginAmerica is probably one of the best air...   \n",
       "\n",
       "                                        text_stemmed  \n",
       "0     @161252 what' that egg websit peopl talk about  \n",
       "1  why!ü§∑üèª‚Äç‚ôÄÔ∏è #ios11 @applesupport https://t.co/bx...  \n",
       "2  @693975 We can assist you. We recommend updat ...  \n",
       "3  @331912 @115955 that better than have an unsta...  \n",
       "4  @virginamerica is probabl one of the best airl...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Drop the two columns \n",
    "df.drop([\"text_wo_stopfreq\", \"text_wo_stopfreqrare\"], axis=1, inplace=True) \n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "df[\"text_stemmed\"] = df[\"text\"].apply(lambda text: stem_words(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that words like private and propose have their e at the end chopped off due to stemming. This is not intented. What can we do fort hat? We can use Lemmatization in such cases.\n",
    "\n",
    "Also this porter stemmer is for English language. If we are working with other languages, we can use snowball stemmer. The supported languages for snowball stemmer are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "SnowballStemmer.languages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "Lemmatization is similar to stemming in reducing inflected words to their word stem but differs in the way that it makes sure the root word (also called as lemma) belongs to the language.\n",
    "\n",
    "As a result, this one is generally slower than stemming process. So depending on the speed requirement, we can choose to use either stemming or lemmatization.\n",
    "\n",
    "Let us use the WordNetLemmatizer in nltk to lemmatize our sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@161252 What's that egg website people talk about</td>\n",
       "      <td>@161252 what' that egg websit peopl talk about</td>\n",
       "      <td>@161252 What's that egg website people talk about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...</td>\n",
       "      <td>why!ü§∑üèª‚Äç‚ôÄÔ∏è #ios11 @applesupport https://t.co/bx...</td>\n",
       "      <td>Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@693975 We can assist you. We recommend updati...</td>\n",
       "      <td>@693975 We can assist you. We recommend updat ...</td>\n",
       "      <td>@693975 We can assist you. We recommend updati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@331912 @115955 Thats better than having an un...</td>\n",
       "      <td>@331912 @115955 that better than have an unsta...</td>\n",
       "      <td>@331912 @115955 Thats better than having an un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica is probably one of the best air...</td>\n",
       "      <td>@virginamerica is probabl one of the best airl...</td>\n",
       "      <td>@VirginAmerica is probably one of the best air...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @161252 What's that egg website people talk about   \n",
       "1  Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...   \n",
       "2  @693975 We can assist you. We recommend updati...   \n",
       "3  @331912 @115955 Thats better than having an un...   \n",
       "4  @VirginAmerica is probably one of the best air...   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0     @161252 what' that egg websit peopl talk about   \n",
       "1  why!ü§∑üèª‚Äç‚ôÄÔ∏è #ios11 @applesupport https://t.co/bx...   \n",
       "2  @693975 We can assist you. We recommend updat ...   \n",
       "3  @331912 @115955 that better than have an unsta...   \n",
       "4  @virginamerica is probabl one of the best airl...   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0  @161252 What's that egg website people talk about  \n",
       "1  Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...  \n",
       "2  @693975 We can assist you. We recommend updati...  \n",
       "3  @331912 @115955 Thats better than having an un...  \n",
       "4  @VirginAmerica is probably one of the best air...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "df[\"text_lemmatized\"] = df[\"text\"].apply(lambda text: lemmatize_words(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the trailing e in the propose and private is retained when we use lemmatization unlike stemming.\n",
    "\n",
    "Wait. There is one more thing in lemmatization. Let us try to lemmatize running now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'running'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"running\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. It returned running as such without converting it to the root form run. This is because the lemmatization process depends on the POS tag to come up with the correct lemma. Now let us lemmatize again by providing the POS tag for the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"running\", \"v\") # v for verb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redo the lemmatization process with POS tag for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@161252 What's that egg website people talk about</td>\n",
       "      <td>@161252 what' that egg websit peopl talk about</td>\n",
       "      <td>@161252 What's that egg website people talk about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...</td>\n",
       "      <td>why!ü§∑üèª‚Äç‚ôÄÔ∏è #ios11 @applesupport https://t.co/bx...</td>\n",
       "      <td>Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@693975 We can assist you. We recommend updati...</td>\n",
       "      <td>@693975 We can assist you. We recommend updat ...</td>\n",
       "      <td>@693975 We can assist you. We recommend update...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@331912 @115955 Thats better than having an un...</td>\n",
       "      <td>@331912 @115955 that better than have an unsta...</td>\n",
       "      <td>@331912 @115955 Thats good than have an unstab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica is probably one of the best air...</td>\n",
       "      <td>@virginamerica is probabl one of the best airl...</td>\n",
       "      <td>@VirginAmerica be probably one of the best air...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @161252 What's that egg website people talk about   \n",
       "1  Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...   \n",
       "2  @693975 We can assist you. We recommend updati...   \n",
       "3  @331912 @115955 Thats better than having an un...   \n",
       "4  @VirginAmerica is probably one of the best air...   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0     @161252 what' that egg websit peopl talk about   \n",
       "1  why!ü§∑üèª‚Äç‚ôÄÔ∏è #ios11 @applesupport https://t.co/bx...   \n",
       "2  @693975 We can assist you. We recommend updat ...   \n",
       "3  @331912 @115955 that better than have an unsta...   \n",
       "4  @virginamerica is probabl one of the best airl...   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0  @161252 What's that egg website people talk about  \n",
       "1  Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BX...  \n",
       "2  @693975 We can assist you. We recommend update...  \n",
       "3  @331912 @115955 Thats good than have an unstab...  \n",
       "4  @VirginAmerica be probably one of the best air...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "\n",
    "def lemmatize_words(text):\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "\n",
    "df[\"text_lemmatized\"] = df[\"text\"].apply(lambda text: lemmatize_words(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of Emojis\n",
    "\n",
    "With more and more usage of social media platforms, there is an explosion in the usage of emojis in our day to day life as well. Probably we might need to remove these emojis for some of our textual analysis.\n",
    "\n",
    "Thanks to [this code](https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b), please find below a helper function to remove emojis from our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'game is on '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "remove_emoji(\"game is on üî•üî•\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hilarious'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"HilariousüòÇ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of URLs\n",
    "\n",
    "Next preprocessing step is to remove any URLs present in the data. For example, if we are doing a twitter analysis, then there is a good chance that the tweet will have some URL in it. Probably we might need to remove them for our further analysis.\n",
    "\n",
    "We can use the below code snippet to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a https link and check the code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Driverless AI NLP blog post on '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Driverless AI NLP blog post on https://www.h2o.ai/blog/detecting-sarcasm-is-difficult-but-ai-may-have-an-answer/\"\n",
    "remove_urls(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion activity:\n",
    "\n",
    "* What usecases can you think for NLP?\n",
    "* What role does preprocessing play in the application of NLP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
